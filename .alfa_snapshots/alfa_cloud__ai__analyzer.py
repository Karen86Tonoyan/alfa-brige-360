"""
ğŸ“Š ALFA CLOUD ANALYZER
Analizator plikÃ³w i danych z wykorzystaniem lokalnego AI
"""

from __future__ import annotations
import os
import json
import mimetypes
from pathlib import Path
from dataclasses import dataclass
from typing import Optional, Dict, List, Any
from datetime import datetime
import logging

from alfa_cloud.ai.local_llm import LocalLLM, SystemPrompts


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# DATA CLASSES
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

@dataclass
class AnalysisResult:
    """Wynik analizy"""
    file_path: str
    file_type: str
    analysis: str
    summary: Optional[str] = None
    keywords: List[str] = None
    sentiment: Optional[str] = None
    language: Optional[str] = None
    confidence: float = 0.0
    timestamp: str = ""
    
    def __post_init__(self):
        if not self.timestamp:
            self.timestamp = datetime.now().isoformat()
        if self.keywords is None:
            self.keywords = []
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            "file_path": self.file_path,
            "file_type": self.file_type,
            "analysis": self.analysis,
            "summary": self.summary,
            "keywords": self.keywords,
            "sentiment": self.sentiment,
            "language": self.language,
            "confidence": self.confidence,
            "timestamp": self.timestamp
        }


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# ANALYZER
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

class Analyzer:
    """
    ğŸ“Š Analizator plikÃ³w i danych
    
    Wykorzystuje lokalne AI (Ollama) do:
    - Analizy treÅ›ci plikÃ³w tekstowych
    - Summaryzacji dokumentÃ³w
    - Ekstrakcji sÅ‚Ã³w kluczowych
    - Analizy sentymentu
    - Rozpoznawania jÄ™zyka
    - Analizy obrazÃ³w (z modelem vision)
    """
    
    # ObsÅ‚ugiwane typy plikÃ³w
    TEXT_EXTENSIONS = {'.txt', '.md', '.json', '.yaml', '.yml', '.csv', 
                       '.py', '.js', '.ts', '.html', '.css', '.xml',
                       '.log', '.ini', '.cfg', '.conf'}
    
    IMAGE_EXTENSIONS = {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.webp'}
    
    def __init__(self, llm: Optional[LocalLLM] = None):
        self.llm = llm or LocalLLM()
        self.logger = logging.getLogger("ALFA_CLOUD.Analyzer")
    
    async def analyze_file(self, file_path: str) -> AnalysisResult:
        """
        Analizuje plik na podstawie typu
        """
        path = Path(file_path)
        
        if not path.exists():
            return AnalysisResult(
                file_path=file_path,
                file_type="unknown",
                analysis="[ERROR: Plik nie istnieje]"
            )
        
        # OkreÅ›l typ pliku
        ext = path.suffix.lower()
        mime_type, _ = mimetypes.guess_type(str(path))
        
        # Analizuj wedÅ‚ug typu
        if ext in self.TEXT_EXTENSIONS or (mime_type and mime_type.startswith('text/')):
            return await self._analyze_text_file(path)
        
        elif ext in self.IMAGE_EXTENSIONS or (mime_type and mime_type.startswith('image/')):
            return await self._analyze_image_file(path)
        
        else:
            return AnalysisResult(
                file_path=file_path,
                file_type=mime_type or "binary",
                analysis=f"Nie moÅ¼na przeanalizowaÄ‡ pliku typu: {ext}"
            )
    
    async def _analyze_text_file(self, path: Path) -> AnalysisResult:
        """Analizuje plik tekstowy"""
        try:
            # Wczytaj treÅ›Ä‡
            content = path.read_text(encoding='utf-8', errors='ignore')
            
            # Ogranicz dÅ‚ugoÅ›Ä‡ dla AI
            max_chars = 8000
            if len(content) > max_chars:
                content = content[:max_chars] + "\n[... tekst skrÃ³cony ...]"
            
            # Generuj analizÄ™
            prompt = f"""Przeanalizuj poniÅ¼szy tekst z pliku "{path.name}":

---
{content}
---

Podaj:
1. PODSUMOWANIE (2-3 zdania)
2. SÅOWA KLUCZOWE (5-10)
3. TYP TREÅšCI (np. kod, dokumentacja, log, notatki)
4. JÄ˜ZYK (polski, angielski, mieszany)
5. GÅÃ“WNE TEMATY

Odpowiedz w formacie JSON."""

            analysis = await self.llm.generate(
                prompt,
                system=SystemPrompts.FILE_ANALYZER,
                task="analysis"
            )
            
            # SprÃ³buj sparsowaÄ‡ JSON
            summary = None
            keywords = []
            language = None
            
            try:
                # ZnajdÅº JSON w odpowiedzi
                if '{' in analysis:
                    json_start = analysis.index('{')
                    json_end = analysis.rindex('}') + 1
                    json_str = analysis[json_start:json_end]
                    data = json.loads(json_str)
                    
                    summary = data.get("PODSUMOWANIE") or data.get("summary")
                    keywords = data.get("SÅOWA KLUCZOWE") or data.get("keywords") or []
                    language = data.get("JÄ˜ZYK") or data.get("language")
            except:
                pass
            
            return AnalysisResult(
                file_path=str(path),
                file_type=path.suffix,
                analysis=analysis,
                summary=summary,
                keywords=keywords if isinstance(keywords, list) else [],
                language=language,
                confidence=0.8
            )
            
        except Exception as e:
            self.logger.error(f"BÅ‚Ä…d analizy tekstu: {e}")
            return AnalysisResult(
                file_path=str(path),
                file_type=path.suffix,
                analysis=f"[ERROR: {str(e)}]"
            )
    
    async def _analyze_image_file(self, path: Path) -> AnalysisResult:
        """Analizuje plik obrazu"""
        try:
            analysis = await self.llm.analyze_image(
                str(path),
                prompt="Opisz szczegÃ³Å‚owo co widzisz na tym obrazie. Podaj obiekty, kolory, kompozycjÄ™ i nastrÃ³j."
            )
            
            return AnalysisResult(
                file_path=str(path),
                file_type="image",
                analysis=analysis,
                confidence=0.7
            )
            
        except Exception as e:
            self.logger.error(f"BÅ‚Ä…d analizy obrazu: {e}")
            return AnalysisResult(
                file_path=str(path),
                file_type="image",
                analysis=f"[ERROR: {str(e)}]"
            )
    
    async def summarize(self, text: str, max_sentences: int = 3) -> str:
        """
        Generuje podsumowanie tekstu
        """
        prompt = f"""Napisz zwiÄ™zÅ‚e podsumowanie poniÅ¼szego tekstu w maksymalnie {max_sentences} zdaniach:

{text}

PODSUMOWANIE:"""

        return await self.llm.generate(prompt, task="fast")
    
    async def extract_keywords(self, text: str, max_keywords: int = 10) -> List[str]:
        """
        Ekstrahuje sÅ‚owa kluczowe
        """
        prompt = f"""WyodrÄ™bnij {max_keywords} najwaÅ¼niejszych sÅ‚Ã³w kluczowych z poniÅ¼szego tekstu.
ZwrÃ³Ä‡ tylko listÄ™ sÅ‚Ã³w, oddzielonych przecinkami:

{text}

SÅOWA KLUCZOWE:"""

        response = await self.llm.generate(prompt, task="fast")
        
        # Parsuj odpowiedÅº
        keywords = [k.strip() for k in response.split(',')]
        return keywords[:max_keywords]
    
    async def detect_language(self, text: str) -> str:
        """
        Wykrywa jÄ™zyk tekstu
        """
        prompt = f"""Wykryj jÄ™zyk poniÅ¼szego tekstu. 
Odpowiedz jednym sÅ‚owem (np. "polski", "angielski", "niemiecki"):

{text[:500]}

JÄ˜ZYK:"""

        response = await self.llm.generate(prompt, task="fast")
        return response.strip().lower()
    
    async def analyze_sentiment(self, text: str) -> Dict[str, Any]:
        """
        Analizuje sentyment tekstu
        """
        prompt = f"""Przeanalizuj sentyment poniÅ¼szego tekstu.
Odpowiedz w formacie JSON z polami: sentiment (positive/negative/neutral), score (0-1), keywords:

{text}

JSON:"""

        response = await self.llm.generate(prompt, task="analysis")
        
        try:
            if '{' in response:
                json_start = response.index('{')
                json_end = response.rindex('}') + 1
                return json.loads(response[json_start:json_end])
        except:
            pass
        
        return {"sentiment": "neutral", "score": 0.5, "raw": response}
    
    async def compare_files(self, file1: str, file2: str) -> str:
        """
        PorÃ³wnuje dwa pliki tekstowe
        """
        path1 = Path(file1)
        path2 = Path(file2)
        
        if not path1.exists() or not path2.exists():
            return "[ERROR: Jeden z plikÃ³w nie istnieje]"
        
        content1 = path1.read_text(encoding='utf-8', errors='ignore')[:4000]
        content2 = path2.read_text(encoding='utf-8', errors='ignore')[:4000]
        
        prompt = f"""PorÃ³wnaj dwa poniÅ¼sze teksty i opisz rÃ³Å¼nice:

=== PLIK 1: {path1.name} ===
{content1}

=== PLIK 2: {path2.name} ===
{content2}

ANALIZA RÃ“Å»NIC:"""

        return await self.llm.generate(prompt, task="analysis")


# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
# AI PACKAGE
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

__all__ = ['LocalLLM', 'LocalLLMConfig', 'Analyzer', 'AnalysisResult', 'SystemPrompts']
