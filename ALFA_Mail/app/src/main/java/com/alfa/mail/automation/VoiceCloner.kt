package com.alfa.mail.automation

import android.content.Context
import android.media.AudioFormat
import android.media.AudioRecord
import android.media.AudioTrack
import android.media.MediaRecorder
import android.os.Environment
import kotlinx.coroutines.*
import org.json.JSONArray
import org.json.JSONObject
import java.io.*
import java.net.HttpURLConnection
import java.net.URL
import java.nio.ByteBuffer
import java.nio.ByteOrder
import java.security.MessageDigest
import java.util.*
import kotlin.math.*

/**
 * üé§ ALFA VOICE CLONER v2.0
 * 
 * Profesjonalne klonowanie g≈Çosu z wykorzystaniem:
 * ‚úÖ Nagrywanie pr√≥bek g≈Çosu (min 30 sekund)
 * ‚úÖ Analiza spektralna (FFT)
 * ‚úÖ Ekstrakcja cech g≈Çosowych (MFCC)
 * ‚úÖ Tworzenie profilu g≈Çosowego
 * ‚úÖ Synteza mowy z klonowanym g≈Çosem
 * ‚úÖ Integracja z ElevenLabs / Coqui TTS
 * ‚úÖ Lokalne przetwarzanie dla prywatno≈õci
 */
class VoiceCloner private constructor(private val context: Context) {
    
    companion object {
        @Volatile
        private var INSTANCE: VoiceCloner? = null
        
        fun getInstance(context: Context): VoiceCloner {
            return INSTANCE ?: synchronized(this) {
                INSTANCE ?: VoiceCloner(context.applicationContext).also { INSTANCE = it }
            }
        }
        
        // Audio parameters
        private const val SAMPLE_RATE = 44100
        private const val CHANNEL_CONFIG = AudioFormat.CHANNEL_IN_MONO
        private const val AUDIO_FORMAT = AudioFormat.ENCODING_PCM_16BIT
        private const val MIN_SAMPLES_SECONDS = 30
        
        // API endpoints
        private const val ELEVENLABS_API = "https://api.elevenlabs.io/v1"
        private const val COQUI_API = "https://api.coqui.ai/v1"
    }
    
    // Voice profiles storage
    private val voiceProfiles = mutableMapOf<String, VoiceProfile>()
    private val prefs = context.getSharedPreferences("voice_cloner", Context.MODE_PRIVATE)
    
    // Recording state
    private var audioRecord: AudioRecord? = null
    private var isRecording = false
    private var recordingJob: Job? = null
    
    init {
        loadSavedProfiles()
    }
    
    // ============================================================
    // DATA CLASSES
    // ============================================================
    
    data class VoiceProfile(
        val id: String = UUID.randomUUID().toString(),
        val name: String,
        val createdAt: Long = System.currentTimeMillis(),
        val samplePath: String,
        val sampleDurationMs: Long,
        val characteristics: VoiceCharacteristics,
        val embeddingPath: String? = null,
        val apiVoiceId: String? = null, // ID from ElevenLabs/Coqui
        val isLocal: Boolean = true
    )
    
    data class VoiceCharacteristics(
        val pitchHz: Float,           // Podstawowa czƒôstotliwo≈õƒá
        val pitchRange: Float,         // Zakres tonu
        val speakingRate: Float,       // Tempo m√≥wienia (s≈Ç√≥w/min)
        val energy: Float,             // ≈örednia energia g≈Çosu
        val formants: List<Float>,     // Formanty F1-F4
        val mfcc: List<Float>,         // Mel-Frequency Cepstral Coefficients
        val jitter: Float,             // Zmienno≈õƒá czƒôstotliwo≈õci
        val shimmer: Float,            // Zmienno≈õƒá amplitudy
        val harmonicsToNoise: Float,   // Stosunek harmonicznych do szumu
        val voiceType: VoiceType
    )
    
    enum class VoiceType {
        BASS,           // Niski mƒôski
        BARITONE,       // ≈öredni mƒôski
        TENOR,          // Wysoki mƒôski
        ALTO,           // Niski ≈ºe≈Ñski
        MEZZO_SOPRANO,  // ≈öredni ≈ºe≈Ñski
        SOPRANO,        // Wysoki ≈ºe≈Ñski
        CHILD,          // Dzieciƒôcy
        UNKNOWN
    }
    
    data class SynthesisRequest(
        val text: String,
        val voiceProfileId: String,
        val speed: Float = 1.0f,
        val pitch: Float = 1.0f,
        val emotion: Emotion = Emotion.NEUTRAL,
        val outputFormat: OutputFormat = OutputFormat.WAV
    )
    
    enum class Emotion {
        NEUTRAL, HAPPY, SAD, ANGRY, EXCITED, CALM, WHISPER
    }
    
    enum class OutputFormat {
        WAV, MP3, OGG, FLAC
    }
    
    data class SynthesisResult(
        val success: Boolean,
        val audioPath: String? = null,
        val durationMs: Long = 0,
        val error: String? = null
    )
    
    data class RecordingProgress(
        val elapsedSeconds: Int,
        val requiredSeconds: Int,
        val amplitude: Float,
        val isComplete: Boolean
    )
    
    // ============================================================
    // RECORDING FUNCTIONS
    // ============================================================
    
    /**
     * Rozpoczyna nagrywanie pr√≥bki g≈Çosu
     */
    suspend fun startRecording(
        profileName: String,
        onProgress: (RecordingProgress) -> Unit
    ): Result<String> = withContext(Dispatchers.IO) {
        try {
            val bufferSize = AudioRecord.getMinBufferSize(
                SAMPLE_RATE, CHANNEL_CONFIG, AUDIO_FORMAT
            ) * 2
            
            audioRecord = AudioRecord(
                MediaRecorder.AudioSource.MIC,
                SAMPLE_RATE,
                CHANNEL_CONFIG,
                AUDIO_FORMAT,
                bufferSize
            )
            
            if (audioRecord?.state != AudioRecord.STATE_INITIALIZED) {
                return@withContext Result.failure(Exception("Nie mo≈ºna zainicjalizowaƒá nagrywania"))
            }
            
            // Przygotuj plik wyj≈õciowy
            val outputDir = File(context.filesDir, "voice_samples")
            outputDir.mkdirs()
            val outputFile = File(outputDir, "sample_${System.currentTimeMillis()}.wav")
            
            isRecording = true
            audioRecord?.startRecording()
            
            val audioData = ByteArrayOutputStream()
            val buffer = ByteArray(bufferSize)
            var totalBytes = 0
            val startTime = System.currentTimeMillis()
            
            while (isRecording) {
                val bytesRead = audioRecord?.read(buffer, 0, buffer.size) ?: 0
                
                if (bytesRead > 0) {
                    audioData.write(buffer, 0, bytesRead)
                    totalBytes += bytesRead
                    
                    // Oblicz postƒôp
                    val elapsedMs = System.currentTimeMillis() - startTime
                    val elapsedSeconds = (elapsedMs / 1000).toInt()
                    
                    // Oblicz amplitudƒô (RMS)
                    val amplitude = calculateRMS(buffer, bytesRead)
                    
                    onProgress(RecordingProgress(
                        elapsedSeconds = elapsedSeconds,
                        requiredSeconds = MIN_SAMPLES_SECONDS,
                        amplitude = amplitude,
                        isComplete = elapsedSeconds >= MIN_SAMPLES_SECONDS
                    ))
                    
                    // Automatyczne zatrzymanie po osiƒÖgniƒôciu minimum
                    if (elapsedSeconds >= MIN_SAMPLES_SECONDS * 2) {
                        break
                    }
                }
                
                delay(50) // Ma≈Çe op√≥≈∫nienie dla UI
            }
            
            // Zatrzymaj nagrywanie
            audioRecord?.stop()
            audioRecord?.release()
            audioRecord = null
            isRecording = false
            
            // Zapisz jako WAV
            val wavData = createWavFile(audioData.toByteArray())
            FileOutputStream(outputFile).use { it.write(wavData) }
            
            val durationMs = System.currentTimeMillis() - startTime
            
            // Analizuj i stw√≥rz profil
            val characteristics = analyzeVoice(audioData.toByteArray())
            
            val profile = VoiceProfile(
                name = profileName,
                samplePath = outputFile.absolutePath,
                sampleDurationMs = durationMs,
                characteristics = characteristics
            )
            
            voiceProfiles[profile.id] = profile
            saveProfile(profile)
            
            Result.success(profile.id)
            
        } catch (e: Exception) {
            isRecording = false
            audioRecord?.release()
            audioRecord = null
            Result.failure(e)
        }
    }
    
    /**
     * Zatrzymuje nagrywanie
     */
    fun stopRecording() {
        isRecording = false
    }
    
    /**
     * Tworzy plik WAV z surowych danych PCM
     */
    private fun createWavFile(pcmData: ByteArray): ByteArray {
        val totalDataLen = pcmData.size + 36
        val byteRate = SAMPLE_RATE * 2 // 16-bit mono
        
        val header = ByteBuffer.allocate(44).apply {
            order(ByteOrder.LITTLE_ENDIAN)
            
            // RIFF header
            put("RIFF".toByteArray())
            putInt(totalDataLen)
            put("WAVE".toByteArray())
            
            // fmt subchunk
            put("fmt ".toByteArray())
            putInt(16) // Subchunk1Size
            putShort(1) // AudioFormat (PCM)
            putShort(1) // NumChannels (mono)
            putInt(SAMPLE_RATE)
            putInt(byteRate)
            putShort(2) // BlockAlign
            putShort(16) // BitsPerSample
            
            // data subchunk
            put("data".toByteArray())
            putInt(pcmData.size)
        }
        
        return header.array() + pcmData
    }
    
    // ============================================================
    // VOICE ANALYSIS
    // ============================================================
    
    /**
     * Analizuje pr√≥bkƒô g≈Çosu i ekstrahuje cechy
     */
    private fun analyzeVoice(audioData: ByteArray): VoiceCharacteristics {
        // Konwertuj bajty na pr√≥bki float
        val samples = bytesToFloatArray(audioData)
        
        // Oblicz podstawowe parametry
        val pitch = estimatePitch(samples)
        val energy = calculateEnergy(samples)
        val formants = estimateFormants(samples)
        val mfcc = calculateMFCC(samples)
        val jitter = calculateJitter(samples)
        val shimmer = calculateShimmer(samples)
        val hnr = calculateHNR(samples)
        
        // Okre≈õl typ g≈Çosu na podstawie czƒôstotliwo≈õci podstawowej
        val voiceType = classifyVoiceType(pitch)
        
        return VoiceCharacteristics(
            pitchHz = pitch,
            pitchRange = estimatePitchRange(samples),
            speakingRate = estimateSpeakingRate(samples),
            energy = energy,
            formants = formants,
            mfcc = mfcc,
            jitter = jitter,
            shimmer = shimmer,
            harmonicsToNoise = hnr,
            voiceType = voiceType
        )
    }
    
    /**
     * Konwertuje bajty audio na tablicƒô float
     */
    private fun bytesToFloatArray(bytes: ByteArray): FloatArray {
        val shorts = ShortArray(bytes.size / 2)
        ByteBuffer.wrap(bytes).order(ByteOrder.LITTLE_ENDIAN).asShortBuffer().get(shorts)
        
        return FloatArray(shorts.size) { shorts[it] / 32768.0f }
    }
    
    /**
     * Estymuje czƒôstotliwo≈õƒá podstawowƒÖ (pitch) metodƒÖ autokorelacji
     */
    private fun estimatePitch(samples: FloatArray): Float {
        if (samples.size < 1024) return 0f
        
        val frameSize = 1024
        val minLag = (SAMPLE_RATE / 500).toInt() // Max 500Hz
        val maxLag = (SAMPLE_RATE / 50).toInt()  // Min 50Hz
        
        var maxCorr = 0f
        var bestLag = 0
        
        // Autokorelacja
        for (lag in minLag until minOf(maxLag, samples.size - frameSize)) {
            var corr = 0f
            for (i in 0 until frameSize) {
                corr += samples[i] * samples[i + lag]
            }
            
            if (corr > maxCorr) {
                maxCorr = corr
                bestLag = lag
            }
        }
        
        return if (bestLag > 0) SAMPLE_RATE.toFloat() / bestLag else 0f
    }
    
    /**
     * Estymuje zakres tonu (pitch range)
     */
    private fun estimatePitchRange(samples: FloatArray): Float {
        val frameSize = 1024
        val hopSize = 512
        val pitches = mutableListOf<Float>()
        
        var i = 0
        while (i + frameSize < samples.size) {
            val frame = samples.sliceArray(i until i + frameSize)
            val pitch = estimatePitch(frame)
            if (pitch > 50 && pitch < 500) {
                pitches.add(pitch)
            }
            i += hopSize
        }
        
        return if (pitches.size > 2) {
            pitches.sorted().let { sorted ->
                sorted[sorted.size * 95 / 100] - sorted[sorted.size * 5 / 100]
            }
        } else 0f
    }
    
    /**
     * Oblicza energiƒô sygna≈Çu (RMS)
     */
    private fun calculateEnergy(samples: FloatArray): Float {
        if (samples.isEmpty()) return 0f
        var sum = 0f
        for (sample in samples) {
            sum += sample * sample
        }
        return sqrt(sum / samples.size)
    }
    
    /**
     * Oblicza RMS z bufora bajt√≥w
     */
    private fun calculateRMS(buffer: ByteArray, length: Int): Float {
        var sum = 0.0
        for (i in 0 until length step 2) {
            if (i + 1 < length) {
                val sample = (buffer[i].toInt() and 0xFF) or (buffer[i + 1].toInt() shl 8)
                sum += sample * sample
            }
        }
        return sqrt(sum / (length / 2)).toFloat() / 32768f
    }
    
    /**
     * Estymuje formanty (F1-F4) metodƒÖ LPC
     */
    private fun estimateFormants(samples: FloatArray): List<Float> {
        // Uproszczona estymacja formant√≥w
        // W pe≈Çnej implementacji u≈ºyliby≈õmy LPC (Linear Predictive Coding)
        
        val fftSize = 2048
        if (samples.size < fftSize) return listOf(500f, 1500f, 2500f, 3500f)
        
        // FFT frame
        val frame = samples.sliceArray(0 until fftSize)
        val spectrum = computeFFT(frame)
        
        // Znajd≈∫ szczyty spektralne (formanty)
        val peaks = findSpectralPeaks(spectrum, 4)
        
        return peaks.map { it * SAMPLE_RATE.toFloat() / fftSize }
    }
    
    /**
     * Oblicza MFCC (Mel-Frequency Cepstral Coefficients)
     */
    private fun calculateMFCC(samples: FloatArray, numCoeffs: Int = 13): List<Float> {
        val frameSize = 1024
        if (samples.size < frameSize) return List(numCoeffs) { 0f }
        
        // 1. Pre-emphasis
        val preEmph = FloatArray(samples.size)
        preEmph[0] = samples[0]
        for (i in 1 until samples.size) {
            preEmph[i] = samples[i] - 0.97f * samples[i - 1]
        }
        
        // 2. Windowing (Hamming)
        val frame = FloatArray(frameSize)
        for (i in 0 until frameSize) {
            frame[i] = preEmph[i] * (0.54f - 0.46f * cos(2.0 * PI * i / (frameSize - 1))).toFloat()
        }
        
        // 3. FFT
        val spectrum = computeFFT(frame)
        
        // 4. Mel filterbank
        val melFilters = createMelFilterbank(26, frameSize, SAMPLE_RATE)
        val melEnergies = FloatArray(26)
        for (i in melFilters.indices) {
            melEnergies[i] = spectrum.zip(melFilters[i]).map { it.first * it.second }.sum()
        }
        
        // 5. Log
        for (i in melEnergies.indices) {
            melEnergies[i] = ln(melEnergies[i].coerceAtLeast(1e-10f))
        }
        
        // 6. DCT
        val mfcc = FloatArray(numCoeffs)
        for (i in 0 until numCoeffs) {
            for (j in melEnergies.indices) {
                mfcc[i] += melEnergies[j] * cos(PI * i * (j + 0.5) / melEnergies.size).toFloat()
            }
        }
        
        return mfcc.toList()
    }
    
    /**
     * Tworzy mel filterbank
     */
    private fun createMelFilterbank(numFilters: Int, fftSize: Int, sampleRate: Int): List<FloatArray> {
        fun hzToMel(hz: Float) = 2595 * log10(1 + hz / 700)
        fun melToHz(mel: Float) = 700 * (10f.pow(mel / 2595) - 1)
        
        val lowMel = hzToMel(0f)
        val highMel = hzToMel(sampleRate / 2f)
        val melPoints = FloatArray(numFilters + 2) { i ->
            melToHz(lowMel + i * (highMel - lowMel) / (numFilters + 1))
        }
        
        val binPoints = melPoints.map { (it * fftSize / sampleRate).toInt() }
        
        return List(numFilters) { i ->
            FloatArray(fftSize / 2) { k ->
                when {
                    k < binPoints[i] -> 0f
                    k < binPoints[i + 1] -> (k - binPoints[i]).toFloat() / (binPoints[i + 1] - binPoints[i])
                    k < binPoints[i + 2] -> (binPoints[i + 2] - k).toFloat() / (binPoints[i + 2] - binPoints[i + 1])
                    else -> 0f
                }
            }
        }
    }
    
    /**
     * Oblicza jitter (zmienno≈õƒá czƒôstotliwo≈õci)
     */
    private fun calculateJitter(samples: FloatArray): Float {
        val pitches = mutableListOf<Float>()
        val frameSize = 1024
        var i = 0
        
        while (i + frameSize < samples.size) {
            val frame = samples.sliceArray(i until i + frameSize)
            val pitch = estimatePitch(frame)
            if (pitch > 50 && pitch < 500) {
                pitches.add(pitch)
            }
            i += frameSize / 2
        }
        
        if (pitches.size < 3) return 0f
        
        var jitterSum = 0f
        for (j in 1 until pitches.size) {
            jitterSum += abs(pitches[j] - pitches[j - 1])
        }
        
        return jitterSum / (pitches.size - 1) / pitches.average().toFloat() * 100
    }
    
    /**
     * Oblicza shimmer (zmienno≈õƒá amplitudy)
     */
    private fun calculateShimmer(samples: FloatArray): Float {
        val amplitudes = mutableListOf<Float>()
        val frameSize = 1024
        var i = 0
        
        while (i + frameSize < samples.size) {
            val frame = samples.sliceArray(i until i + frameSize)
            amplitudes.add(frame.maxOrNull() ?: 0f)
            i += frameSize / 2
        }
        
        if (amplitudes.size < 3) return 0f
        
        var shimmerSum = 0f
        for (j in 1 until amplitudes.size) {
            shimmerSum += abs(amplitudes[j] - amplitudes[j - 1])
        }
        
        return shimmerSum / (amplitudes.size - 1) / amplitudes.average().toFloat() * 100
    }
    
    /**
     * Oblicza stosunek harmonicznych do szumu (HNR)
     */
    private fun calculateHNR(samples: FloatArray): Float {
        if (samples.size < 2048) return 0f
        
        val frame = samples.sliceArray(0 until 2048)
        val spectrum = computeFFT(frame)
        
        // Estymuj szum jako dolny percentyl spektrum
        val sorted = spectrum.sorted()
        val noiseFloor = sorted[sorted.size / 10]
        
        // Harmoniczne jako energia powy≈ºej szumu
        val harmonicEnergy = spectrum.filter { it > noiseFloor * 2 }.sum()
        val noiseEnergy = spectrum.filter { it <= noiseFloor * 2 }.sum()
        
        return if (noiseEnergy > 0) 10 * log10(harmonicEnergy / noiseEnergy) else 0f
    }
    
    /**
     * Estymuje tempo m√≥wienia
     */
    private fun estimateSpeakingRate(samples: FloatArray): Float {
        // Uproszczona estymacja na podstawie energii
        val frameSize = 1024
        val hopSize = 256
        var syllableCount = 0
        var wasLow = true
        val threshold = calculateEnergy(samples) * 0.5f
        
        var i = 0
        while (i + frameSize < samples.size) {
            val frame = samples.sliceArray(i until i + frameSize)
            val energy = calculateEnergy(frame)
            
            if (energy > threshold && wasLow) {
                syllableCount++
                wasLow = false
            } else if (energy < threshold * 0.5f) {
                wasLow = true
            }
            i += hopSize
        }
        
        val durationSeconds = samples.size.toFloat() / SAMPLE_RATE
        val syllablesPerSecond = syllableCount / durationSeconds
        
        // Zak≈ÇadajƒÖc ≈õrednio 1.5 sylaby na s≈Çowo
        return syllablesPerSecond / 1.5f * 60 // s≈Ç√≥w na minutƒô
    }
    
    /**
     * Klasyfikuje typ g≈Çosu
     */
    private fun classifyVoiceType(pitchHz: Float): VoiceType {
        return when {
            pitchHz < 85 -> VoiceType.BASS
            pitchHz < 130 -> VoiceType.BARITONE
            pitchHz < 180 -> VoiceType.TENOR
            pitchHz < 220 -> VoiceType.ALTO
            pitchHz < 280 -> VoiceType.MEZZO_SOPRANO
            pitchHz < 350 -> VoiceType.SOPRANO
            pitchHz < 400 -> VoiceType.CHILD
            else -> VoiceType.UNKNOWN
        }
    }
    
    /**
     * Proste FFT (Cooley-Tukey)
     */
    private fun computeFFT(samples: FloatArray): FloatArray {
        val n = samples.size
        if (n == 1) return floatArrayOf(abs(samples[0]))
        
        // Padding do potƒôgi 2
        val paddedSize = Integer.highestOneBit(n - 1) shl 1
        val padded = samples.copyOf(paddedSize)
        
        // Butterfly FFT
        val real = padded.copyOf()
        val imag = FloatArray(paddedSize)
        
        // Bit-reversal
        var j = 0
        for (i in 0 until paddedSize - 1) {
            if (i < j) {
                val temp = real[i]
                real[i] = real[j]
                real[j] = temp
            }
            var k = paddedSize / 2
            while (k <= j) {
                j -= k
                k /= 2
            }
            j += k
        }
        
        // FFT
        var step = 1
        while (step < paddedSize) {
            val delta = -PI.toFloat() / step
            for (group in 0 until paddedSize step step * 2) {
                var angle = 0f
                for (pair in 0 until step) {
                    val i = group + pair
                    val k = i + step
                    val cos = cos(angle)
                    val sin = sin(angle)
                    val tr = real[k] * cos - imag[k] * sin
                    val ti = real[k] * sin + imag[k] * cos
                    real[k] = real[i] - tr
                    imag[k] = imag[i] - ti
                    real[i] += tr
                    imag[i] += ti
                    angle += delta
                }
            }
            step *= 2
        }
        
        // Magnitude spectrum
        return FloatArray(paddedSize / 2) { i ->
            sqrt(real[i] * real[i] + imag[i] * imag[i])
        }
    }
    
    /**
     * Znajduje szczyty w spektrum
     */
    private fun findSpectralPeaks(spectrum: FloatArray, numPeaks: Int): List<Int> {
        val peaks = mutableListOf<Pair<Int, Float>>()
        
        for (i in 1 until spectrum.size - 1) {
            if (spectrum[i] > spectrum[i - 1] && spectrum[i] > spectrum[i + 1]) {
                peaks.add(i to spectrum[i])
            }
        }
        
        return peaks.sortedByDescending { it.second }
            .take(numPeaks)
            .map { it.first }
            .sorted()
    }
    
    // ============================================================
    // SYNTHESIS (TTS z klonowanym g≈Çosem)
    // ============================================================
    
    /**
     * Syntezuje mowƒô z klonowanym g≈Çosem
     */
    suspend fun synthesize(request: SynthesisRequest): SynthesisResult = withContext(Dispatchers.IO) {
        val profile = voiceProfiles[request.voiceProfileId]
            ?: return@withContext SynthesisResult(false, error = "Profil g≈Çosu nie znaleziony")
        
        try {
            // Sprawd≈∫ czy mamy API voice ID
            if (profile.apiVoiceId != null) {
                return@withContext synthesizeWithElevenLabs(request, profile)
            }
            
            // Lokalna synteza (podstawowa)
            synthesizeLocal(request, profile)
            
        } catch (e: Exception) {
            SynthesisResult(false, error = e.message)
        }
    }
    
    /**
     * Synteza przez ElevenLabs API
     */
    private suspend fun synthesizeWithElevenLabs(
        request: SynthesisRequest,
        profile: VoiceProfile
    ): SynthesisResult = withContext(Dispatchers.IO) {
        val apiKey = prefs.getString("elevenlabs_api_key", null)
            ?: return@withContext SynthesisResult(false, error = "Brak klucza API ElevenLabs")
        
        try {
            val url = URL("$ELEVENLABS_API/text-to-speech/${profile.apiVoiceId}")
            val conn = url.openConnection() as HttpURLConnection
            
            conn.requestMethod = "POST"
            conn.setRequestProperty("xi-api-key", apiKey)
            conn.setRequestProperty("Content-Type", "application/json")
            conn.doOutput = true
            
            val body = JSONObject().apply {
                put("text", request.text)
                put("model_id", "eleven_multilingual_v2")
                put("voice_settings", JSONObject().apply {
                    put("stability", 0.5)
                    put("similarity_boost", 0.8)
                    put("style", when (request.emotion) {
                        Emotion.HAPPY -> 0.8
                        Emotion.SAD -> 0.2
                        Emotion.ANGRY -> 0.9
                        Emotion.CALM -> 0.3
                        else -> 0.5
                    })
                })
            }
            
            conn.outputStream.write(body.toString().toByteArray())
            
            if (conn.responseCode == 200) {
                val outputDir = File(context.filesDir, "synthesized")
                outputDir.mkdirs()
                val outputFile = File(outputDir, "synth_${System.currentTimeMillis()}.mp3")
                
                conn.inputStream.use { input ->
                    FileOutputStream(outputFile).use { output ->
                        input.copyTo(output)
                    }
                }
                
                SynthesisResult(
                    success = true,
                    audioPath = outputFile.absolutePath,
                    durationMs = estimateAudioDuration(outputFile)
                )
            } else {
                val error = conn.errorStream?.bufferedReader()?.readText() ?: "Unknown error"
                SynthesisResult(false, error = "API Error: $error")
            }
            
        } catch (e: Exception) {
            SynthesisResult(false, error = e.message)
        }
    }
    
    /**
     * Lokalna synteza (podstawowa - bez klonowania)
     */
    private fun synthesizeLocal(request: SynthesisRequest, profile: VoiceProfile): SynthesisResult {
        // Podstawowa synteza lokalna - w przysz≈Ço≈õci integracja z Coqui TTS
        return SynthesisResult(
            false, 
            error = "Lokalna synteza wymaga integracji z Coqui TTS. U≈ºyj API ElevenLabs."
        )
    }
    
    /**
     * Przesy≈Ça pr√≥bkƒô g≈Çosu do ElevenLabs i tworzy voice clone
     */
    suspend fun uploadToElevenLabs(profileId: String): Result<String> = withContext(Dispatchers.IO) {
        val profile = voiceProfiles[profileId]
            ?: return@withContext Result.failure(Exception("Profil nie znaleziony"))
        
        val apiKey = prefs.getString("elevenlabs_api_key", null)
            ?: return@withContext Result.failure(Exception("Brak klucza API"))
        
        try {
            val url = URL("$ELEVENLABS_API/voices/add")
            val conn = url.openConnection() as HttpURLConnection
            
            conn.requestMethod = "POST"
            conn.setRequestProperty("xi-api-key", apiKey)
            conn.doOutput = true
            
            val boundary = "----${UUID.randomUUID()}"
            conn.setRequestProperty("Content-Type", "multipart/form-data; boundary=$boundary")
            
            val outputStream = conn.outputStream
            val writer = PrintWriter(OutputStreamWriter(outputStream, "UTF-8"), true)
            
            // Name field
            writer.append("--$boundary\r\n")
            writer.append("Content-Disposition: form-data; name=\"name\"\r\n\r\n")
            writer.append("${profile.name}\r\n")
            
            // Description
            writer.append("--$boundary\r\n")
            writer.append("Content-Disposition: form-data; name=\"description\"\r\n\r\n")
            writer.append("ALFA Voice Clone - ${profile.characteristics.voiceType}\r\n")
            
            // Audio file
            writer.append("--$boundary\r\n")
            writer.append("Content-Disposition: form-data; name=\"files\"; filename=\"sample.wav\"\r\n")
            writer.append("Content-Type: audio/wav\r\n\r\n")
            writer.flush()
            
            FileInputStream(profile.samplePath).use { it.copyTo(outputStream) }
            
            writer.append("\r\n--$boundary--\r\n")
            writer.flush()
            
            if (conn.responseCode == 200) {
                val response = conn.inputStream.bufferedReader().readText()
                val json = JSONObject(response)
                val voiceId = json.getString("voice_id")
                
                // Zaktualizuj profil z voice ID
                val updatedProfile = profile.copy(apiVoiceId = voiceId, isLocal = false)
                voiceProfiles[profileId] = updatedProfile
                saveProfile(updatedProfile)
                
                Result.success(voiceId)
            } else {
                val error = conn.errorStream?.bufferedReader()?.readText() ?: "Unknown error"
                Result.failure(Exception(error))
            }
            
        } catch (e: Exception) {
            Result.failure(e)
        }
    }
    
    // ============================================================
    // PROFILE MANAGEMENT
    // ============================================================
    
    fun getProfile(id: String): VoiceProfile? = voiceProfiles[id]
    
    fun getAllProfiles(): List<VoiceProfile> = voiceProfiles.values.toList()
    
    fun deleteProfile(id: String): Boolean {
        val profile = voiceProfiles.remove(id) ?: return false
        
        // Usu≈Ñ plik pr√≥bki
        File(profile.samplePath).delete()
        
        // Usu≈Ñ z preferences
        val saved = prefs.getStringSet("profile_ids", mutableSetOf()) ?: mutableSetOf()
        saved.remove(id)
        prefs.edit().putStringSet("profile_ids", saved).apply()
        prefs.edit().remove("profile_$id").apply()
        
        return true
    }
    
    fun setElevenLabsApiKey(apiKey: String) {
        prefs.edit().putString("elevenlabs_api_key", apiKey).apply()
    }
    
    private fun saveProfile(profile: VoiceProfile) {
        val json = JSONObject().apply {
            put("id", profile.id)
            put("name", profile.name)
            put("createdAt", profile.createdAt)
            put("samplePath", profile.samplePath)
            put("sampleDurationMs", profile.sampleDurationMs)
            put("apiVoiceId", profile.apiVoiceId)
            put("isLocal", profile.isLocal)
            put("characteristics", JSONObject().apply {
                put("pitchHz", profile.characteristics.pitchHz)
                put("pitchRange", profile.characteristics.pitchRange)
                put("speakingRate", profile.characteristics.speakingRate)
                put("energy", profile.characteristics.energy)
                put("formants", JSONArray(profile.characteristics.formants))
                put("mfcc", JSONArray(profile.characteristics.mfcc))
                put("jitter", profile.characteristics.jitter)
                put("shimmer", profile.characteristics.shimmer)
                put("harmonicsToNoise", profile.characteristics.harmonicsToNoise)
                put("voiceType", profile.characteristics.voiceType.name)
            })
        }
        
        val ids = prefs.getStringSet("profile_ids", mutableSetOf())?.toMutableSet() ?: mutableSetOf()
        ids.add(profile.id)
        
        prefs.edit()
            .putStringSet("profile_ids", ids)
            .putString("profile_${profile.id}", json.toString())
            .apply()
    }
    
    private fun loadSavedProfiles() {
        val ids = prefs.getStringSet("profile_ids", emptySet()) ?: return
        
        for (id in ids) {
            val json = prefs.getString("profile_$id", null) ?: continue
            try {
                val obj = JSONObject(json)
                val chars = obj.getJSONObject("characteristics")
                
                val profile = VoiceProfile(
                    id = obj.getString("id"),
                    name = obj.getString("name"),
                    createdAt = obj.getLong("createdAt"),
                    samplePath = obj.getString("samplePath"),
                    sampleDurationMs = obj.getLong("sampleDurationMs"),
                    apiVoiceId = obj.optString("apiVoiceId").takeIf { it.isNotEmpty() },
                    isLocal = obj.optBoolean("isLocal", true),
                    characteristics = VoiceCharacteristics(
                        pitchHz = chars.getDouble("pitchHz").toFloat(),
                        pitchRange = chars.getDouble("pitchRange").toFloat(),
                        speakingRate = chars.getDouble("speakingRate").toFloat(),
                        energy = chars.getDouble("energy").toFloat(),
                        formants = (0 until chars.getJSONArray("formants").length()).map {
                            chars.getJSONArray("formants").getDouble(it).toFloat()
                        },
                        mfcc = (0 until chars.getJSONArray("mfcc").length()).map {
                            chars.getJSONArray("mfcc").getDouble(it).toFloat()
                        },
                        jitter = chars.getDouble("jitter").toFloat(),
                        shimmer = chars.getDouble("shimmer").toFloat(),
                        harmonicsToNoise = chars.getDouble("harmonicsToNoise").toFloat(),
                        voiceType = VoiceType.valueOf(chars.getString("voiceType"))
                    )
                )
                
                voiceProfiles[id] = profile
                
            } catch (e: Exception) {
                // Skip invalid profiles
            }
        }
    }
    
    private fun estimateAudioDuration(file: File): Long {
        // Szacowanie na podstawie rozmiaru pliku MP3 (≈õrednio 128kbps)
        return (file.length() * 8 / 128).toLong()
    }
}
