package com.alfa.mail.ai

import android.content.Context
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.withContext
import org.json.JSONArray
import org.json.JSONObject
import java.net.HttpURLConnection
import java.net.URL

/**
 * ü§ñ AI ASSIST SERVICE
 * 
 * Inteligentne sugestie dla emaili:
 * - Gemini API (online)
 * - Ollama (local, offline)
 * - Szablony (fallback)
 */
class AiAssistService private constructor(private val context: Context) {
    
    enum class AiProvider {
        GEMINI,     // Google Gemini API
        OLLAMA,     // Local Ollama
        OPENAI,     // OpenAI (backup)
        TEMPLATE    // Offline templates
    }
    
    data class AiConfig(
        val provider: AiProvider = AiProvider.GEMINI,
        val geminiApiKey: String? = null,
        val ollamaUrl: String = "http://localhost:11434",
        val ollamaModel: String = "llama3",
        val openaiApiKey: String? = null
    )
    
    sealed class AiResult {
        data class Success(val text: String, val provider: AiProvider) : AiResult()
        data class Error(val message: String) : AiResult()
    }
    
    // üß† Streaming result z widocznymi my≈õlami (jak DeepSeek)
    data class ThinkingStep(
        val thought: String,
        val timestamp: Long = System.currentTimeMillis()
    )
    
    data class StreamingResult(
        val thoughts: MutableList<ThinkingStep> = mutableListOf(),
        val finalText: String = "",
        val isComplete: Boolean = false,
        val error: String? = null
    )
    
    private var config: AiConfig = AiConfig()
    
    companion object {
        @Volatile
        private var instance: AiAssistService? = null
        
        fun getInstance(context: Context): AiAssistService {
            return instance ?: synchronized(this) {
                instance ?: AiAssistService(context.applicationContext).also { instance = it }
            }
        }
        
        // Szablony dla r√≥≈ºnych typ√≥w emaili
        private val TEMPLATES = mapOf(
            "formal" to """
                Szanowny/a Panie/Pani,
                
                [Tre≈õƒá wiadomo≈õci]
                
                Z powa≈ºaniem,
                [Twoje imiƒô]
            """.trimIndent(),
            
            "informal" to """
                Cze≈õƒá!
                
                [Tre≈õƒá wiadomo≈õci]
                
                Pozdrawiam,
                [Twoje imiƒô]
            """.trimIndent(),
            
            "business" to """
                Dzie≈Ñ dobry,
                
                W nawiƒÖzaniu do [temat], chcia≈Çbym/chcia≈Çabym [cel wiadomo≈õci].
                
                [Szczeg√≥≈Çy]
                
                Czekam na odpowied≈∫.
                
                Z powa≈ºaniem,
                [Twoje imiƒô]
                [Stanowisko]
            """.trimIndent(),
            
            "thank_you" to """
                Szanowny/a [imiƒô],
                
                Dziƒôkujƒô za [pow√≥d podziƒôkowania].
                
                [Opcjonalnie: szczeg√≥≈Çy]
                
                Jeszcze raz dziƒôkujƒô i pozdrawiam,
                [Twoje imiƒô]
            """.trimIndent(),
            
            "follow_up" to """
                Dzie≈Ñ dobry,
                
                NawiƒÖzujƒô do naszej poprzedniej rozmowy/wymiany emaili dotyczƒÖcej [temat].
                
                Chcia≈Çbym/chcia≈Çabym zapytaƒá o aktualny status [sprawa].
                
                Czekam na informacjƒô.
                
                Z powa≈ºaniem,
                [Twoje imiƒô]
            """.trimIndent(),
            
            "apology" to """
                Szanowny/a [imiƒô],
                
                Przepraszam za [pow√≥d przeprosin].
                
                [Wyja≈õnienie sytuacji]
                
                [Propozycja rozwiƒÖzania]
                
                Mam nadziejƒô na zrozumienie.
                
                Z powa≈ºaniem,
                [Twoje imiƒô]
            """.trimIndent()
        )
    }
    
    /**
     * Konfiguruj AI
     */
    fun configure(newConfig: AiConfig) {
        config = newConfig
    }
    
    /**
     * Za≈Çaduj konfiguracjƒô z storage
     */
    suspend fun loadConfig(): Boolean {
        return withContext(Dispatchers.IO) {
            try {
                val prefs = context.getSharedPreferences("alfa_ai_config", Context.MODE_PRIVATE)
                val provider = AiProvider.valueOf(prefs.getString("provider", "GEMINI") ?: "GEMINI")
                
                config = AiConfig(
                    provider = provider,
                    geminiApiKey = prefs.getString("gemini_key", null),
                    ollamaUrl = prefs.getString("ollama_url", "http://localhost:11434") ?: "http://localhost:11434",
                    ollamaModel = prefs.getString("ollama_model", "llama3") ?: "llama3",
                    openaiApiKey = prefs.getString("openai_key", null)
                )
                true
            } catch (e: Exception) {
                false
            }
        }
    }
    
    /**
     * Sugestia dla emaila
     */
    suspend fun suggestEmail(
        context: EmailContext,
        style: String = "professional"
    ): AiResult {
        val prompt = buildPrompt(context, style)
        
        // Pr√≥buj r√≥≈ºne providery
        return when (config.provider) {
            AiProvider.GEMINI -> {
                val result = tryGemini(prompt)
                if (result is AiResult.Error) tryOllama(prompt) else result
            }
            AiProvider.OLLAMA -> {
                val result = tryOllama(prompt)
                if (result is AiResult.Error) tryTemplate(context, style) else result
            }
            AiProvider.OPENAI -> {
                val result = tryOpenAI(prompt)
                if (result is AiResult.Error) tryGemini(prompt) else result
            }
            AiProvider.TEMPLATE -> tryTemplate(context, style)
        }
    }
    
    /**
     * Popraw email
     */
    suspend fun improveEmail(
        currentBody: String,
        instruction: String = "Popraw ten email, zachowujƒÖc sens ale ulepszajƒÖc styl"
    ): AiResult {
        val prompt = """
            $instruction
            
            Oryginalny email:
            $currentBody
            
            Poprawiony email:
        """.trimIndent()
        
        return when (config.provider) {
            AiProvider.GEMINI -> tryGemini(prompt)
            AiProvider.OLLAMA -> tryOllama(prompt)
            AiProvider.OPENAI -> tryOpenAI(prompt)
            AiProvider.TEMPLATE -> AiResult.Success(currentBody, AiProvider.TEMPLATE)
        }
    }
    
    /**
     * Generuj temat emaila
     */
    suspend fun suggestSubject(body: String): AiResult {
        val prompt = """
            Wygeneruj kr√≥tki, profesjonalny temat emaila dla poni≈ºszej tre≈õci.
            Odpowiedz TYLKO tematem, bez dodatkowego tekstu.
            
            Tre≈õƒá:
            $body
        """.trimIndent()
        
        return when (config.provider) {
            AiProvider.GEMINI -> tryGemini(prompt)
            AiProvider.OLLAMA -> tryOllama(prompt)
            AiProvider.OPENAI -> tryOpenAI(prompt)
            AiProvider.TEMPLATE -> AiResult.Success("Re: Wiadomo≈õƒá", AiProvider.TEMPLATE)
        }
    }
    
    /**
     * Automatyczne odpowiedzi
     */
    suspend fun suggestReply(
        originalEmail: String,
        replyIntent: String = "positive" // positive, negative, neutral, question
    ): AiResult {
        val intentDescription = when (replyIntent) {
            "positive" -> "pozytywna, zgadzajƒÖca siƒô"
            "negative" -> "grzeczna odmowa"
            "neutral" -> "neutralna, informacyjna"
            "question" -> "pytajƒÖca o wiƒôcej szczeg√≥≈Ç√≥w"
            else -> "profesjonalna"
        }
        
        val prompt = """
            Napisz $intentDescription odpowied≈∫ na poni≈ºszy email.
            Zachowaj profesjonalny ton.
            
            Oryginalny email:
            $originalEmail
            
            Odpowied≈∫:
        """.trimIndent()
        
        return when (config.provider) {
            AiProvider.GEMINI -> tryGemini(prompt)
            AiProvider.OLLAMA -> tryOllama(prompt)
            else -> tryTemplate(EmailContext("", "", "reply"), "formal")
        }
    }
    
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // PROVIDERS
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    private suspend fun tryGemini(prompt: String): AiResult {
        val apiKey = config.geminiApiKey ?: return AiResult.Error("Gemini API key not configured")
        
        return withContext(Dispatchers.IO) {
            try {
                val url = URL("https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:generateContent?key=$apiKey")
                val connection = url.openConnection() as HttpURLConnection
                
                connection.apply {
                    requestMethod = "POST"
                    setRequestProperty("Content-Type", "application/json")
                    doOutput = true
                    connectTimeout = 15000
                    readTimeout = 30000
                }
                
                val requestBody = JSONObject().apply {
                    put("contents", JSONArray().apply {
                        put(JSONObject().apply {
                            put("parts", JSONArray().apply {
                                put(JSONObject().apply {
                                    put("text", prompt)
                                })
                            })
                        })
                    })
                }
                
                connection.outputStream.use { os ->
                    os.write(requestBody.toString().toByteArray())
                }
                
                if (connection.responseCode == 200) {
                    val response = connection.inputStream.bufferedReader().readText()
                    val json = JSONObject(response)
                    val text = json.getJSONArray("candidates")
                        .getJSONObject(0)
                        .getJSONObject("content")
                        .getJSONArray("parts")
                        .getJSONObject(0)
                        .getString("text")
                    
                    AiResult.Success(text.trim(), AiProvider.GEMINI)
                } else {
                    val error = connection.errorStream?.bufferedReader()?.readText() ?: "Unknown error"
                    AiResult.Error("Gemini error: $error")
                }
            } catch (e: Exception) {
                AiResult.Error("Gemini failed: ${e.message}")
            }
        }
    }
    
    private suspend fun tryOllama(prompt: String): AiResult {
        return withContext(Dispatchers.IO) {
            try {
                val url = URL("${config.ollamaUrl}/api/generate")
                val connection = url.openConnection() as HttpURLConnection
                
                connection.apply {
                    requestMethod = "POST"
                    setRequestProperty("Content-Type", "application/json")
                    doOutput = true
                    connectTimeout = 5000
                    readTimeout = 60000
                }
                
                val requestBody = JSONObject().apply {
                    put("model", config.ollamaModel)
                    put("prompt", prompt)
                    put("stream", false)
                }
                
                connection.outputStream.use { os ->
                    os.write(requestBody.toString().toByteArray())
                }
                
                if (connection.responseCode == 200) {
                    val response = connection.inputStream.bufferedReader().readText()
                    val json = JSONObject(response)
                    val text = json.getString("response")
                    
                    AiResult.Success(text.trim(), AiProvider.OLLAMA)
                } else {
                    AiResult.Error("Ollama error: ${connection.responseCode}")
                }
            } catch (e: Exception) {
                AiResult.Error("Ollama unavailable: ${e.message}")
            }
        }
    }
    
    private suspend fun tryOpenAI(prompt: String): AiResult {
        val apiKey = config.openaiApiKey ?: return AiResult.Error("OpenAI API key not configured")
        
        return withContext(Dispatchers.IO) {
            try {
                val url = URL("https://api.openai.com/v1/chat/completions")
                val connection = url.openConnection() as HttpURLConnection
                
                connection.apply {
                    requestMethod = "POST"
                    setRequestProperty("Content-Type", "application/json")
                    setRequestProperty("Authorization", "Bearer $apiKey")
                    doOutput = true
                    connectTimeout = 15000
                    readTimeout = 30000
                }
                
                val requestBody = JSONObject().apply {
                    put("model", "gpt-3.5-turbo")
                    put("messages", JSONArray().apply {
                        put(JSONObject().apply {
                            put("role", "user")
                            put("content", prompt)
                        })
                    })
                    put("max_tokens", 1000)
                }
                
                connection.outputStream.use { os ->
                    os.write(requestBody.toString().toByteArray())
                }
                
                if (connection.responseCode == 200) {
                    val response = connection.inputStream.bufferedReader().readText()
                    val json = JSONObject(response)
                    val text = json.getJSONArray("choices")
                        .getJSONObject(0)
                        .getJSONObject("message")
                        .getString("content")
                    
                    AiResult.Success(text.trim(), AiProvider.OPENAI)
                } else {
                    AiResult.Error("OpenAI error: ${connection.responseCode}")
                }
            } catch (e: Exception) {
                AiResult.Error("OpenAI failed: ${e.message}")
            }
        }
    }
    
    private fun tryTemplate(context: EmailContext, style: String): AiResult {
        val template = TEMPLATES[style] ?: TEMPLATES["formal"]!!
        return AiResult.Success(template, AiProvider.TEMPLATE)
    }
    
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // HELPERS
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    data class EmailContext(
        val to: String,
        val subject: String,
        val purpose: String, // e.g., "request", "thank_you", "inquiry"
        val additionalContext: String = ""
    )
    
    private fun buildPrompt(context: EmailContext, style: String): String {
        val styleDescription = when (style) {
            "formal" -> "formalny, oficjalny"
            "informal" -> "nieformalny, przyjazny"
            "business" -> "biznesowy, profesjonalny"
            "friendly" -> "przyjacielski, ciep≈Çy"
            else -> "profesjonalny"
        }
        
        return """
            Napisz email w stylu: $styleDescription
            
            Odbiorca: ${context.to}
            Temat: ${context.subject}
            Cel: ${context.purpose}
            ${if (context.additionalContext.isNotEmpty()) "Dodatkowy kontekst: ${context.additionalContext}" else ""}
            
            Napisz TYLKO tre≈õƒá emaila, bez tematu i nag≈Ç√≥wk√≥w.
            Email powinien byƒá w jƒôzyku polskim.
        """.trimIndent()
    }
    
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    // üß† STREAMING Z WIDOCZNYMI MY≈öLAMI (JAK DEEPSEEK)
    // ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    
    /**
     * Streamuj generowanie emaila z widocznymi my≈õlami AI
     */
    suspend fun suggestEmailStreaming(
        context: EmailContext,
        style: String = "professional",
        onThought: (ThinkingStep) -> Unit,
        onProgress: (String) -> Unit,
        onComplete: (String) -> Unit,
        onError: (String) -> Unit
    ) {
        return when (config.provider) {
            AiProvider.GEMINI -> streamGemini(context, style, onThought, onProgress, onComplete, onError)
            AiProvider.OLLAMA -> streamOllama(context, style, onThought, onProgress, onComplete, onError)
            else -> {
                // Fallback bez streaming
                onThought(ThinkingStep("üí≠ U≈ºywam lokalnych szablon√≥w..."))
                kotlinx.coroutines.delay(300)
                val result = tryTemplate(context, style)
                when (result) {
                    is AiResult.Success -> {
                        onThought(ThinkingStep("‚úÖ Szablon za≈Çadowany!"))
                        onComplete(result.text)
                    }
                    is AiResult.Error -> onError(result.message)
                }
            }
        }
    }
    
    /**
     * Streamuj poprawƒô emaila z my≈õlami
     */
    suspend fun improveEmailStreaming(
        currentBody: String,
        onThought: (ThinkingStep) -> Unit,
        onProgress: (String) -> Unit,
        onComplete: (String) -> Unit,
        onError: (String) -> Unit
    ) {
        onThought(ThinkingStep("ü§î Analizujƒô oryginalny email..."))
        kotlinx.coroutines.delay(200)
        onThought(ThinkingStep("üìè D≈Çugo≈õƒá: ${currentBody.length} znak√≥w"))
        kotlinx.coroutines.delay(200)
        
        val prompt = """
            Popraw ten email, zachowujƒÖc sens ale ulepszajƒÖc styl.
            Pomy≈õl krok po kroku jak go poprawiƒá.
            
            Oryginalny email:
            $currentBody
            
            Poprawiony email:
        """.trimIndent()
        
        when (config.provider) {
            AiProvider.GEMINI -> streamGeminiRaw(prompt, onThought, onProgress, onComplete, onError)
            AiProvider.OLLAMA -> streamOllamaRaw(prompt, onThought, onProgress, onComplete, onError)
            else -> {
                onThought(ThinkingStep("‚ö†Ô∏è Brak AI, zwracam oryginalny tekst"))
                onComplete(currentBody)
            }
        }
    }
    
    // Gemini streaming implementation
    private suspend fun streamGemini(
        context: EmailContext,
        style: String,
        onThought: (ThinkingStep) -> Unit,
        onProgress: (String) -> Unit,
        onComplete: (String) -> Unit,
        onError: (String) -> Unit
    ) = withContext(Dispatchers.IO) {
        try {
            onThought(ThinkingStep("ü§î Analizujƒô kontekst emaila..."))
            kotlinx.coroutines.delay(300)
            onThought(ThinkingStep("üìù Odbiorca: ${context.to}"))
            kotlinx.coroutines.delay(200)
            onThought(ThinkingStep("üìã Temat: ${context.subject}"))
            kotlinx.coroutines.delay(200)
            onThought(ThinkingStep("üé® Styl: $style"))
            kotlinx.coroutines.delay(300)
            
            val prompt = buildPrompt(context, style)
            streamGeminiRaw(prompt, onThought, onProgress, onComplete, onError)
        } catch (e: Exception) {
            onError("Gemini error: ${e.message}")
        }
    }
    
    private suspend fun streamGeminiRaw(
        prompt: String,
        onThought: (ThinkingStep) -> Unit,
        onProgress: (String) -> Unit,
        onComplete: (String) -> Unit,
        onError: (String) -> Unit
    ) = withContext(Dispatchers.IO) {
        try {
            val apiKey = config.geminiApiKey
            if (apiKey.isNullOrBlank()) {
                onError("Brak klucza API Gemini")
                return@withContext
            }
            
            onThought(ThinkingStep("üîÆ ≈ÅƒÖczƒô siƒô z Gemini API..."))
            kotlinx.coroutines.delay(200)
            
            val url = URL("https://generativelanguage.googleapis.com/v1beta/models/gemini-pro:streamGenerateContent?key=$apiKey&alt=sse")
            val connection = url.openConnection() as HttpURLConnection
            connection.requestMethod = "POST"
            connection.setRequestProperty("Content-Type", "application/json")
            connection.doOutput = true
            
            val jsonBody = JSONObject().apply {
                put("contents", JSONArray().apply {
                    put(JSONObject().apply {
                        put("parts", JSONArray().apply {
                            put(JSONObject().apply {
                                put("text", prompt)
                            })
                        })
                    })
                })
            }.toString()
            
            connection.outputStream.use { it.write(jsonBody.toByteArray()) }
            
            onThought(ThinkingStep("‚ú® Model zaczyna my≈õleƒá..."))
            kotlinx.coroutines.delay(300)
            
            val reader = connection.inputStream.bufferedReader()
            var fullText = ""
            var line: String?
            var lastThoughtTime = System.currentTimeMillis()
            
            while (reader.readLine().also { line = it } != null) {
                if (line!!.startsWith("data: ")) {
                    val data = line!!.substring(6)
                    if (data.trim() != "[DONE]") {
                        try {
                            val json = JSONObject(data)
                            val candidates = json.optJSONArray("candidates")
                            if (candidates != null && candidates.length() > 0) {
                                val content = candidates.getJSONObject(0).optJSONObject("content")
                                val parts = content?.optJSONArray("parts")
                                if (parts != null && parts.length() > 0) {
                                    val text = parts.getJSONObject(0).optString("text", "")
                                    if (text.isNotEmpty()) {
                                        fullText += text
                                        onProgress(fullText)
                                        
                                        // Pokazuj my≈õli co jaki≈õ czas
                                        val now = System.currentTimeMillis()
                                        if (now - lastThoughtTime > 1000) {
                                            onThought(ThinkingStep("‚úçÔ∏è Generujƒô... (${fullText.length} znak√≥w)"))
                                            lastThoughtTime = now
                                        }
                                    }
                                }
                            }
                        } catch (e: Exception) {
                            // Ignoruj b≈Çƒôdy parsowania pojedynczych chunk√≥w
                        }
                    }
                }
            }
            
            if (fullText.isBlank()) {
                onThought(ThinkingStep("‚ö†Ô∏è Streaming niedostƒôpny, pr√≥bujƒô standardowego API..."))
                val result = tryGemini(prompt)
                when (result) {
                    is AiResult.Success -> {
                        onThought(ThinkingStep("‚úÖ Gotowe!"))
                        onComplete(result.text)
                    }
                    is AiResult.Error -> onError(result.message)
                }
            } else {
                onThought(ThinkingStep("‚úÖ Email wygenerowany pomy≈õlnie!"))
                kotlinx.coroutines.delay(300)
                onComplete(fullText)
            }
        } catch (e: Exception) {
            onError("Gemini streaming error: ${e.message}")
        }
    }
    
    // Ollama streaming implementation
    private suspend fun streamOllama(
        context: EmailContext,
        style: String,
        onThought: (ThinkingStep) -> Unit,
        onProgress: (String) -> Unit,
        onComplete: (String) -> Unit,
        onError: (String) -> Unit
    ) = withContext(Dispatchers.IO) {
        try {
            onThought(ThinkingStep("ü§î Analizujƒô ≈ºƒÖdanie..."))
            kotlinx.coroutines.delay(200)
            onThought(ThinkingStep("üìã Kontekst: ${context.to} - ${context.subject}"))
            kotlinx.coroutines.delay(200)
            
            val prompt = buildPrompt(context, style)
            streamOllamaRaw(prompt, onThought, onProgress, onComplete, onError)
        } catch (e: Exception) {
            onError("Ollama error: ${e.message}")
        }
    }
    
    private suspend fun streamOllamaRaw(
        prompt: String,
        onThought: (ThinkingStep) -> Unit,
        onProgress: (String) -> Unit,
        onComplete: (String) -> Unit,
        onError: (String) -> Unit
    ) = withContext(Dispatchers.IO) {
        try {
            onThought(ThinkingStep("üñ•Ô∏è ≈ÅƒÖczƒô siƒô z Ollama (${config.ollamaModel})..."))
            kotlinx.coroutines.delay(200)
            
            val url = URL("${config.ollamaUrl}/api/generate")
            val connection = url.openConnection() as HttpURLConnection
            connection.requestMethod = "POST"
            connection.setRequestProperty("Content-Type", "application/json")
            connection.doOutput = true
            
            val jsonBody = JSONObject().apply {
                put("model", config.ollamaModel)
                put("prompt", prompt)
                put("stream", true)
            }.toString()
            
            connection.outputStream.use { it.write(jsonBody.toByteArray()) }
            
            onThought(ThinkingStep("‚ú® Model lokalny my≈õli..."))
            kotlinx.coroutines.delay(300)
            
            val reader = connection.inputStream.bufferedReader()
            var fullText = ""
            var line: String?
            var lastThoughtTime = System.currentTimeMillis()
            
            while (reader.readLine().also { line = it } != null) {
                try {
                    val json = JSONObject(line!!)
                    val response = json.optString("response", "")
                    if (response.isNotEmpty()) {
                        fullText += response
                        onProgress(fullText)
                        
                        val now = System.currentTimeMillis()
                        if (now - lastThoughtTime > 800) {
                            onThought(ThinkingStep("‚úçÔ∏è Piszƒô... (${fullText.length} znak√≥w)"))
                            lastThoughtTime = now
                        }
                    }
                    
                    if (json.optBoolean("done", false)) {
                        break
                    }
                } catch (e: Exception) {
                    // Ignoruj b≈Çƒôdy parsowania
                }
            }
            
            onThought(ThinkingStep("‚úÖ Zako≈Ñczono generowanie!"))
            kotlinx.coroutines.delay(200)
            onComplete(fullText)
        } catch (e: Exception) {
            onError("Ollama error: ${e.message}")
        }
    }
}

